{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b1934b",
   "metadata": {},
   "source": [
    "#### spatio-temporal downscaling cGAN training script following\n",
    "https://doi.org/10.48550/arXiv.2411.16098 \\\n",
    "https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023EA002906 \\\n",
    "the models, training and validation routines deviate slightly from \\\n",
    "the papers since this notebooks aims to make changes to a specific downscaling problem easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9cb56e-a51d-4709-aa0c-4521887d90b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from models import Generator, Discriminator\n",
    "from types import SimpleNamespace\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43808ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    'batch_size': 2,\n",
    "    'num_epochs': 100,\n",
    "    'save_step': 1000, #save models after every save_step\n",
    "    'eval_step': 50, #validation after every eval_step\n",
    "    'lam': 1, # scale l1loss\n",
    "    'ensemble_size': 2, # number of ensembles member during training\n",
    "    'Discriminator_filter': 16, # 128 in paper, must be divisible by 4\n",
    "    'Generator_filter': 16, # 128 in paper, can be adjusted freely\n",
    "}\n",
    "config = SimpleNamespace(**config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8288442a-e03c-41d2-a166-6e5972b4b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202acce6-9009-4feb-9992-f75fb1f3b0c0",
   "metadata": {},
   "source": [
    "Load some example data to check if model runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514ab63-0d8e-4131-b719-f0d61d1662aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed9490-fcc4-4aa9-be1c-529b42af1a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test_y = xr.open_dataset('data/y_test.nc').load()\n",
    "ds_test_x = xr.open_dataset('data/x_test.nc').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db785cd-94dd-42c2-b121-8d6f2faa8ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust example data, to match model input and target\n",
    "x_test = ds_test_x.cp.values + ds_test_x.lsp.values # total precipitation\n",
    "x_test = x_test[:, 7:-7, 7:-7]\n",
    "x_test = rearrange(x_test, 't h w -> 1 1 t h w')\n",
    "y_test = rearrange(ds_test_y.rainfall_amount.values, 't h w -> 1 1 t h w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.tensor(x_test).to(device).float()\n",
    "y_test = torch.tensor(y_test).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff704e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not torch.isnan(x_test).any(), \"x_test contains NaN values\"\n",
    "assert not torch.isnan(y_test).any(), \"y_test contains NaN values\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78823a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490d95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from continuous time dimension to batches\n",
    "# change to a  dataset that already has the samples with the right dimensions\n",
    "x_chunks = torch.split(x_test, 8, dim=2)\n",
    "x_batched = torch.cat(x_chunks, dim=0)\n",
    "\n",
    "y_chunks = torch.split(y_test, 8*6, dim=2)\n",
    "y_batched = torch.cat(y_chunks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3455995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model gets samples of t=8, w,h = 14 and downscales it to t=48 and w,h = 168 \n",
    "# samples and model architecture can be adjusted to fit different data \n",
    "# Generator upsampling can be adjusted and discriminator downsampling can be adjusted in models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e095708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply normalization to data, if necessary... spateGAN uses norm. data in the discriminator --> implment in train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c0841",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batched.shape, y_batched.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8769db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_train = torch.utils.data.TensorDataset(x_batched, y_batched)\n",
    "# dataloader can also be adjusted to use multiprocessing and loading\n",
    "dm_train = torch.utils.data.DataLoader(dm_train, batch_size=config.batch_size, shuffle=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d826b540",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generator_optimizer(model):\n",
    "    return torch.optim.AdamW(model.parameters(), lr=1e-4, betas=(0.0, 0.999),weight_decay=0.0001)\n",
    "\n",
    "def discriminator_optimizer(model):\n",
    "    return torch.optim.AdamW(model.parameters(), lr=2e-4, betas=(0.5, 0.999),weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e84876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(config, input_image, target, discriminator, generator, gen_opt, disc_opt, scaler, criterion):\n",
    "    \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    gen_opt.zero_grad(set_to_none=True)\n",
    "\n",
    "    ##################################\n",
    "    ########Generator:############\n",
    "    ##################################\n",
    "    \n",
    "    # mixed precission\n",
    "    with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "   \n",
    "        ## generate multiple ensemble prediction-\n",
    "        gen_ensemble = torch.cat([generator(input_image) for _ in range(config.ensemble_size)], dim=1)\n",
    "        \n",
    "        pred = gen_ensemble[:,0:1] # single prediction\n",
    "\n",
    "        # calculate ensemble mean\n",
    "        ensemble_mean = torch.sum(gen_ensemble, dim=1, keepdim=True) / config.ensemble_size\n",
    "\n",
    "         # Classify all fake batch with D\n",
    "        disc_fake_output = discriminator(input_image, pred)\n",
    "        gen_gan_loss = criterion(disc_fake_output, torch.ones_like(disc_fake_output))\n",
    "        \n",
    "        # can also be changed to crps loss, using the indv. ensemble members\n",
    "        l1loss = nn.L1Loss()(ensemble_mean, target)\n",
    "\n",
    "        loss = (l1loss * config.lam  + gen_gan_loss)\n",
    "\n",
    "\n",
    "    scaler.scale(loss).backward()\n",
    "    \n",
    "    # Gradient Norm Clipping\n",
    "    #nn.utils.clip_grad_norm_(generator.parameters(), max_norm=2.0, norm_type=2)\n",
    "    \n",
    "    scaler.step(gen_opt)\n",
    "    scaler.update()\n",
    "        \n",
    "    ##################################\n",
    "    ########Discriminator:############\n",
    "    ##################################\n",
    "    \n",
    "    \n",
    "    # spateGAN uses log normed data for the discriminator, spateGAN-ERA5 does not apply a normalization\n",
    "    # for this min max from the trainings data should be calcualted and used in the config:\n",
    "    \n",
    "    # input_image = torch.log(input_image + 1e-6)\n",
    "    # target = torch.log(target + 1e-6)\n",
    "    # input_image = (input_image - config.min) / (config.max() - config.min())\n",
    "    # target = (target - config.min()) / (config.max() - config.min()) \n",
    "    \n",
    "    disc_opt.zero_grad(set_to_none=True)\n",
    "    \n",
    "\n",
    "    pred = pred.detach()\n",
    "    \n",
    "    # pred = torch.log(pred + 1e-6)\n",
    "    # pred = (pred - config.min) / (config.max() - config.min())\n",
    "    \n",
    "    with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "\n",
    "        # discriminator prediction\n",
    "        disc_real_output = discriminator(input_image, target)\n",
    "        disc_real = criterion(disc_real_output, torch.ones_like(disc_real_output))\n",
    "\n",
    "\n",
    "        # Classify all fake batch with D\n",
    "        disc_fake_output = discriminator(input_image, pred) # \n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        disc_fake = criterion(disc_fake_output, torch.zeros_like(disc_fake_output))\n",
    "\n",
    "   \n",
    "    scaler.scale(disc_fake + disc_real).backward()\n",
    "    \n",
    "    # Gradient Norm Clipping\n",
    "    #nn.utils.clip_grad_norm_(discriminator.parameters(), max_norm=2.0, norm_type=2)\n",
    "    scaler.step(disc_opt)\n",
    "    scaler.update()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf61fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a really simple validation function to plot some predictions and check if the model is learning\n",
    "# Input and targets should be from a separate dataset, not the training data\n",
    "# Scores that i tracked but are not included: Discriminator loss, Generator loss, L1 loss, GAN loss (mainly to check model stability)\n",
    "# FSS, RAPSD, CRPS, RMSE etc... FSS and RAPSD are suitable to select the best performing model state.\n",
    "\n",
    "def validation(config, generator,discriminator, input_image, target, step, plot_folder):\n",
    "    ensemble_size = 1\n",
    "    batch_split = 1\n",
    "\n",
    "    generator.eval()\n",
    "    outputs = []\n",
    "\n",
    "    for _ in range(ensemble_size):\n",
    "        batch_outputs = []\n",
    "        for i in range(0, input_image.size(0), batch_split):\n",
    "            batch = input_image[i:i+batch_split]\n",
    "            with torch.no_grad():\n",
    "                out = generator(batch)\n",
    "            batch_outputs.append(out)\n",
    "        outputs.append(torch.cat(batch_outputs, dim=0))\n",
    "\n",
    "    # cat along dimension 1 for ensemble\n",
    "    ensemble_output = torch.cat(outputs, dim=1) \n",
    "    \n",
    "    \n",
    "    target = target.cpu().detach().numpy()\n",
    "    ensemble_output = ensemble_output.cpu().detach().numpy()\n",
    "    input_image = input_image.cpu().detach().numpy()\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax[0].imshow(input_image[0, 0, 0, :, :], cmap='turbo')\n",
    "    ax[0].set_title('input')\n",
    "    ax[1].imshow(target[0, 0, 0, :, :], cmap='turbo')\n",
    "    ax[1].set_title('target')\n",
    "    ax[2].imshow(ensemble_output[0, 0, 0, :, :], cmap='turbo')\n",
    "    ax[2].set_title('output')\n",
    "    plt.show()\n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62032756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(config, dm_train):\n",
    "      \n",
    "    generator = Generator(filter_size=config.Generator_filter).to(device)\n",
    "\n",
    "    # wrap to dataparallel\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        generator = nn.DataParallel(generator)\n",
    "\n",
    "    # load optimizer\n",
    "    gen_opt = generator_optimizer(generator)\n",
    "\n",
    "\n",
    "    discriminator = Discriminator(filter_size=config.Discriminator_filter).to(device)\n",
    "\n",
    "    # wrap to dataparallel\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        discriminator = nn.DataParallel(discriminator)\n",
    "\n",
    "    # load optimizer\n",
    "    disc_opt = discriminator_optimizer(discriminator)\n",
    "\n",
    "  \n",
    "    scaler = torch.amp.GradScaler()\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "    \n",
    "    ############################################################\n",
    "    ################MODEL TRAINING##############################\n",
    "    ############################################################\n",
    "    \n",
    "    for epoch in tqdm(range(config.num_epochs)):\n",
    "        \n",
    "        for step, (input_image, target) in enumerate(dm_train):\n",
    "                \n",
    "            train_step(config, input_image, target, discriminator, generator, gen_opt, disc_opt, scaler, criterion)\n",
    "            \n",
    "            full_step = epoch * len(dm_train) + step\n",
    "            \n",
    "        \n",
    "            if full_step % (config.eval_step) == 0:\n",
    "                \n",
    "                ### change to valiudation dataset e.g.:\n",
    "                \n",
    "                # input_val, target_val = next(iter(dm_val))\n",
    "                validation(config, generator,discriminator, input_image, target, step, '')\n",
    "                \n",
    "            ######## save model ########\n",
    "            \n",
    "            if full_step != 0 and full_step % config.save_step == 0:\n",
    "                \n",
    "                if isinstance(discriminator, torch.nn.DataParallel):\n",
    "                    state_dict = discriminator.module.state_dict()\n",
    "                else:\n",
    "                    state_dict = discriminator.state_dict()\n",
    "                    \n",
    "                checkpoint_disc = {\n",
    "                    'state_dict': state_dict,\n",
    "                    'optimizer_state_dict': disc_opt.state_dict(),\n",
    "                    'training_step': full_step,\n",
    "                }\n",
    "                torch.save(checkpoint_disc, \n",
    "                            'model_save/discriminator_{}.pt'.format(full_step),\n",
    "                            )   \n",
    "                print(\"saved model, discrimnator model:\")\n",
    "                \n",
    "                if isinstance(generator, torch.nn.DataParallel):\n",
    "                    state_dict = generator.module.state_dict()\n",
    "                else:\n",
    "                    state_dict = generator.state_dict()\n",
    "        \n",
    "                checkpoint_gen = {\n",
    "                    'state_dict': state_dict,\n",
    "                    'optimizer_state_dict': gen_opt.state_dict(),\n",
    "                    'training_step': full_step,\n",
    "                }\n",
    "                torch.save(checkpoint_gen, \n",
    "                            'model_save/generator_{}.pt'.format(full_step),\n",
    "                            )     \n",
    "                print(\"saved model, generator model:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50db364",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(config, dm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f64adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently missing but important: select best model state based on validation scores.\n",
    "# GANs do not converge like optimizing a regression loss. So an option to deal with it, is to let it run, track if it is stable (e.g. disc loss)\n",
    "# and select the best model from this long run based on different scores.\n",
    "# depending on training time validation can be implmented in the validation function, or can be calculated after training using the saved model states.\n",
    "# For precipitation FSS, and RAPSD are valueable scores to judge the model performance. But of course there are many more scores that can be used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aihydromet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
